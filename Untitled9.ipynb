{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN5MsR_yus3O"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.model.encoder"
      ],
      "metadata": {
        "id": "jc_WpIwgiVfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForMaskedLM,BertTokenizer, pipeline\n",
        "\n",
        "# model=BertForMaskedLM.from_pretrained('sberbank-ai/ruBert-base')\n",
        "generator = pipeline(\"text2text-generation\", model=\"sberbank-ai/ruT5-base\")"
      ],
      "metadata": {
        "id": "POHPIBTBuv7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = 'Привет! Я первокурсник НИТУ МИСИС и увлечен экономикой. Ищу друзей, которые разделяют мою страсть к изучению рынка, финансовому анализу и бизнес-стратегиям. Давайте вместе обсуждать экономические темы, участвовать в стартап-проектах и развивать наши знания в этой увлекательной области!'\n",
        "text2 = 'Привет! Я первокурсник НИТУ МИСИС и увлечен миром наноинженерии. Ищу друзей, которые разделяют мою страсть к нанотехнологиям и микросистемам, чтобы вместе исследовать увлекательные возможности этой области, обсуждать научные идеи и создавать инновации. Давайте вместе строить будущее науки и технологий!'\n",
        "text3 = 'Привет! Я первокурсник НИТУ МИСИС и увлекаюсь компьютерными науками. Ищу друзей, которые разделяют мою страсть к программированию, разработке приложений или исследованию новых технологий. Давайте вместе писать код, решать задачи и создавать будущее в мире технологий!'\n",
        "text4 = 'Привет! Я первокурсник НИТУ МИСИС, увлекаюсь экономикой и финансами. Ищу друзей, с кем можно обсудить экономические теории, следить за финансовыми рынками или просто обменяться опытом в этой области. Давайте вместе исследовать мир экономики и создавать новые идеи!'\n",
        "all_text = [text1, text2, text3, text4]"
      ],
      "metadata": {
        "id": "lNwKiBDKwchF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = generator.tokenizer(text=all_text, return_attention_mask=False, return_tensors='pt', padding=True)['input_ids']\n",
        "data.shape"
      ],
      "metadata": {
        "id": "wORwKyMuxkCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embs = generator.model.encoder(data).last_hidden_state.mean(1)"
      ],
      "metadata": {
        "id": "yRSpSX1WvfSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embs.shape"
      ],
      "metadata": {
        "id": "EUQ26kcJ3rwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "cos = torch.nn.CosineSimilarity(dim=0)\n",
        "cos(sentence_embeddings[1], sentence_embeddings[2])"
      ],
      "metadata": {
        "id": "bQzka8lsvrKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input['attention_mask']"
      ],
      "metadata": {
        "id": "ov73lKaKLTg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_output[0].shape"
      ],
      "metadata": {
        "id": "DWjqibk4LTr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Sentences we want sentence embeddings for\n",
        "# sentences = ['This is an example sentence', 'Each sentence is converted']\n",
        "\n",
        "# # Load model from HuggingFace Hub\n",
        "# tokenizer = AutoTokenizer.from_pretrained('uaritm/multilingual_en_uk_pl_ru')\n",
        "# model = AutoModel.from_pretrained('uaritm/multilingual_en_uk_pl_ru')\n",
        "\n",
        "# # Tokenize sentences\n",
        "# encoded_input = tokenizer(all_text, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# # Compute token embeddings\n",
        "# with torch.no_grad():\n",
        "#     model_output = model(**encoded_input)\n",
        "\n",
        "# Perform pooling. In this case, mean pooling.\n",
        "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "print(\"Sentence embeddings:\")\n",
        "print(sentence_embeddings)"
      ],
      "metadata": {
        "id": "GBuZmSpQ1eUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings.shape"
      ],
      "metadata": {
        "id": "b7tn9rxoG3hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = torch.tensor([])\n",
        "torch.stack((d, sentence_embeddings), 0).shape"
      ],
      "metadata": {
        "id": "aJoH0khVSFzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Emb_Creator:\n",
        "  def __init__(self):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained('uaritm/multilingual_en_uk_pl_ru')\n",
        "    self.model = AutoModel.from_pretrained('uaritm/multilingual_en_uk_pl_ru')\n",
        "    self.cos = torch.nn.CosineSimilarity(dim=0)\n",
        "    self.all_embeddings = torch.tensor([])\n",
        "\n",
        "\n",
        "\n",
        "  def emb_creation(self, man_ancket):\n",
        "    '''\n",
        "    Create embedding for persons(if function get one ancket return vector else tensor with shape [num_ancket, 768])\n",
        "    '''\n",
        "    tokenized_text = self.tokenizer(text=man_ancket, return_attention_mask=False, return_tensors='pt', padding=True)\n",
        "    with torch.no_grad():\n",
        "      model_output = self.model(*tokenized_text)\n",
        "    sentence_embeddings = mean_pooling(model_output, model_output['attention_mask']).squeeze()\n",
        "    self.all_embeddings = torch.stack(all_embeddings, self.all_embeddings)\n",
        "    return sentence_embeddings\n",
        "\n",
        "\n",
        "  def get_cos_sim(self, idx, return_max=True):\n",
        "    '''\n",
        "    func get index of person and return cos_sim of person with every man from BD\n",
        "    '''\n",
        "    man = self.all_embeddings[idx]\n",
        "    indices = torch.tensor([i for i in range(self.all_embeddings.shape[0]) if i != idx])\n",
        "    other_embeddings = torch.index_select(self.all_embeddings, 0, indices)\n",
        "    cosine_arr = cos(man, other_embeddings)\n",
        "    if return_max:\n",
        "      max_sim_idx = torch.topk(cosine_arr, 5).indices\n",
        "      max_sim_person = indices[max_sim_idx]\n",
        "      return max_sim_person\n",
        "    min_sim_idx = torch.topk(1/(cosine_arr*100), 5).indices #I need get min topk but I lazy and I solve invert numbers(I dont want to search min topk method)\n",
        "    min_sim_person = indices[min_sim_idx]\n",
        "    return min_sim_person\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "TxB0dEoySF2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P-fjHP0KS6TW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}